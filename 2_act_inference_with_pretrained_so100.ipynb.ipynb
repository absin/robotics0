{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbfaa117-038a-4b42-8718-69cddcec8685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/jpata/gym-so100.git@integration\n",
      "  Cloning https://github.com/jpata/gym-so100.git (to revision integration) to /tmp/pip-req-build-o766efg9\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/jpata/gym-so100.git /tmp/pip-req-build-o766efg9\n",
      "  Running command git checkout -b integration --track origin/integration\n",
      "  Switched to a new branch 'integration'\n",
      "  Branch 'integration' set up to track remote branch 'integration' from 'origin'.\n",
      "  Resolved https://github.com/jpata/gym-so100.git to commit d3dd545d9bfec4639a6e4c631dc62dee138d35ba\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: gymnasium>=0.29 in ./venv-so100/lib/python3.10/site-packages (from gym_lowcostrobot==0.0.1) (1.0.0)\n",
      "Requirement already satisfied: mujoco>=3.0 in ./venv-so100/lib/python3.10/site-packages (from gym_lowcostrobot==0.0.1) (3.2.7)\n",
      "Requirement already satisfied: PyOpenGL==3.1.1a1 in ./venv-so100/lib/python3.10/site-packages (from gym_lowcostrobot==0.0.1) (3.1.1a1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in ./venv-so100/lib/python3.10/site-packages (from gymnasium>=0.29->gym_lowcostrobot==0.0.1) (2.2.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./venv-so100/lib/python3.10/site-packages (from gymnasium>=0.29->gym_lowcostrobot==0.0.1) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in ./venv-so100/lib/python3.10/site-packages (from gymnasium>=0.29->gym_lowcostrobot==0.0.1) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in ./venv-so100/lib/python3.10/site-packages (from gymnasium>=0.29->gym_lowcostrobot==0.0.1) (0.0.4)\n",
      "Requirement already satisfied: absl-py in ./venv-so100/lib/python3.10/site-packages (from mujoco>=3.0->gym_lowcostrobot==0.0.1) (2.1.0)\n",
      "Requirement already satisfied: etils[epath] in ./venv-so100/lib/python3.10/site-packages (from mujoco>=3.0->gym_lowcostrobot==0.0.1) (1.12.0)\n",
      "Requirement already satisfied: glfw in ./venv-so100/lib/python3.10/site-packages (from mujoco>=3.0->gym_lowcostrobot==0.0.1) (2.8.0)\n",
      "Requirement already satisfied: fsspec in ./venv-so100/lib/python3.10/site-packages (from etils[epath]->mujoco>=3.0->gym_lowcostrobot==0.0.1) (2025.2.0)\n",
      "Requirement already satisfied: importlib_resources in ./venv-so100/lib/python3.10/site-packages (from etils[epath]->mujoco>=3.0->gym_lowcostrobot==0.0.1) (6.5.2)\n",
      "Requirement already satisfied: zipp in ./venv-so100/lib/python3.10/site-packages (from etils[epath]->mujoco>=3.0->gym_lowcostrobot==0.0.1) (3.21.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: imageio in ./venv-so100/lib/python3.10/site-packages (2.37.0)\n",
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: numpy in ./venv-so100/lib/python3.10/site-packages (from imageio) (2.2.3)\n",
      "Requirement already satisfied: pillow>=8.3.2 in ./venv-so100/lib/python3.10/site-packages (from imageio) (11.1.0)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./venv-so100/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in ./venv-so100/lib/python3.10/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in ./venv-so100/lib/python3.10/site-packages (from torch) (2025.2.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./venv-so100/lib/python3.10/site-packages (from torch) (0.6.2)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./venv-so100/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./venv-so100/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./venv-so100/lib/python3.10/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./venv-so100/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv-so100/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv-so100/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, filelock, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
      "Successfully installed filelock-3.17.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 torch-2.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/jpata/gym-so100.git@integration\n",
    "!pip install imageio torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77cfc158-def8-4436-b3d8-fdcee1cfbcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import gym_so100\n",
    "import numpy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91bd914a-4677-4e1e-b001-31d04f879983",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"gym_so100/PushCube-v0\", render_mode=\"human\")\n",
    "observation, info = env.reset()\n",
    "frames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "059f3b9c-d26b-4388-90d7-931088913f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from local directory\n",
      "step=0 reward=-5.32459926506402 terminated=False\n",
      "step=1 reward=-5.372093170162899 terminated=False\n",
      "step=2 reward=-5.540144321841882 terminated=False\n",
      "step=3 reward=-5.698087689052722 terminated=False\n",
      "step=4 reward=-6.884907322121309 terminated=False\n",
      "step=5 reward=-6.881013239445432 terminated=False\n",
      "step=6 reward=-6.857959521922565 terminated=False\n",
      "step=7 reward=-6.844647497256892 terminated=False\n",
      "step=8 reward=-5.818788504558431 terminated=False\n",
      "step=9 reward=-5.753434978289583 terminated=False\n",
      "step=10 reward=-5.734157096465994 terminated=False\n",
      "step=11 reward=-5.795307432858733 terminated=False\n",
      "step=12 reward=-5.977746005789837 terminated=False\n",
      "step=13 reward=-6.187914176257796 terminated=False\n",
      "step=14 reward=-6.134316480585964 terminated=False\n",
      "step=15 reward=-6.112694074209591 terminated=False\n",
      "step=16 reward=-6.093202495994923 terminated=False\n",
      "step=17 reward=-6.0521035037763316 terminated=False\n",
      "step=18 reward=-6.029147152453978 terminated=False\n",
      "step=19 reward=-6.053380828967668 terminated=False\n",
      "step=20 reward=-6.038777547821863 terminated=False\n",
      "step=21 reward=-5.993337657638099 terminated=False\n",
      "step=22 reward=-6.001512970303494 terminated=False\n",
      "step=23 reward=-5.940668928900934 terminated=False\n",
      "step=24 reward=-5.897228097854008 terminated=False\n",
      "step=25 reward=-5.919397079175395 terminated=False\n",
      "step=26 reward=-5.8470480793779185 terminated=False\n",
      "step=27 reward=-5.849171595505913 terminated=False\n",
      "step=28 reward=-5.8217870235488505 terminated=False\n",
      "step=29 reward=-5.818376977436679 terminated=False\n",
      "step=30 reward=-5.736865645599902 terminated=False\n",
      "step=31 reward=-5.739236699764428 terminated=False\n",
      "step=32 reward=-5.71654965945327 terminated=False\n",
      "step=33 reward=-5.7095870514072615 terminated=False\n",
      "step=34 reward=-5.690158841575528 terminated=False\n",
      "step=35 reward=-5.664755118254046 terminated=False\n",
      "step=36 reward=-5.618558450257234 terminated=False\n",
      "step=37 reward=-5.5894435534085485 terminated=False\n",
      "step=38 reward=-5.605252415843905 terminated=False\n",
      "step=39 reward=-5.598975542183249 terminated=False\n",
      "step=40 reward=-5.577377076466868 terminated=False\n",
      "step=41 reward=-5.5662088013338105 terminated=False\n",
      "step=42 reward=-5.535064080592509 terminated=False\n",
      "step=43 reward=-5.514899268399254 terminated=False\n",
      "step=44 reward=-5.490666841490395 terminated=False\n",
      "step=45 reward=-5.470423473264404 terminated=False\n",
      "step=46 reward=-5.466841675498463 terminated=False\n",
      "step=47 reward=-5.450987779100542 terminated=False\n",
      "step=48 reward=-5.430229948260054 terminated=False\n",
      "step=49 reward=-5.432895288810015 terminated=False\n",
      "step=50 reward=-5.404964048388646 terminated=False\n",
      "step=51 reward=-5.40933579500151 terminated=False\n",
      "step=52 reward=-5.393829951196386 terminated=False\n",
      "step=53 reward=-5.37346848248856 terminated=False\n",
      "step=54 reward=-5.383254175139378 terminated=False\n",
      "step=55 reward=-5.349968518081405 terminated=False\n",
      "step=56 reward=-5.348319699930777 terminated=False\n",
      "step=57 reward=-5.34863158826815 terminated=False\n",
      "step=58 reward=-5.323061654024802 terminated=False\n",
      "step=59 reward=-5.32970433313532 terminated=False\n",
      "step=60 reward=-5.296211549685282 terminated=False\n",
      "step=61 reward=-5.286093808680058 terminated=False\n",
      "step=62 reward=-5.272687909947333 terminated=False\n",
      "step=63 reward=-5.285637286700005 terminated=False\n",
      "step=64 reward=-5.267333616658841 terminated=False\n",
      "step=65 reward=-5.240494917222488 terminated=False\n",
      "step=66 reward=-5.227696419931458 terminated=False\n",
      "step=67 reward=-5.226748458922257 terminated=False\n",
      "step=68 reward=-5.215292721045866 terminated=False\n",
      "step=69 reward=-5.222313575262135 terminated=False\n",
      "step=70 reward=-5.193309024518408 terminated=False\n",
      "step=71 reward=-5.189687083354008 terminated=False\n",
      "step=72 reward=-5.185813990003775 terminated=False\n",
      "step=73 reward=-5.175531989366101 terminated=False\n",
      "step=74 reward=-5.163259399963737 terminated=False\n",
      "step=75 reward=-5.139285042185077 terminated=False\n",
      "step=76 reward=-5.145077583371928 terminated=False\n",
      "step=77 reward=-5.14074828231969 terminated=False\n",
      "step=78 reward=-5.129727817790304 terminated=False\n",
      "step=79 reward=-5.119573999689185 terminated=False\n",
      "step=80 reward=-5.121931326670029 terminated=False\n",
      "step=81 reward=-5.1002876373798305 terminated=False\n",
      "step=82 reward=-5.099498488721538 terminated=False\n",
      "step=83 reward=-5.106559448637448 terminated=False\n",
      "step=84 reward=-5.091270607084105 terminated=False\n",
      "step=85 reward=-5.072380139258728 terminated=False\n",
      "step=86 reward=-5.076638300209319 terminated=False\n",
      "step=87 reward=-5.071156951526607 terminated=False\n",
      "step=88 reward=-5.081900968017781 terminated=False\n",
      "step=89 reward=-5.065854249820738 terminated=False\n",
      "step=90 reward=-5.052095263701745 terminated=False\n",
      "step=91 reward=-5.068340186093515 terminated=False\n",
      "step=92 reward=-5.047561161553537 terminated=False\n",
      "step=93 reward=-5.039774989659346 terminated=False\n",
      "step=94 reward=-5.0372357604320595 terminated=False\n",
      "step=95 reward=-5.029556760781026 terminated=False\n",
      "step=96 reward=-5.02964599263106 terminated=False\n",
      "step=97 reward=-5.0273131143847225 terminated=False\n",
      "step=98 reward=-5.01864321854471 terminated=False\n",
      "step=99 reward=-5.010974365017663 terminated=False\n",
      "step=100 reward=-6.185170602614724 terminated=False\n",
      "step=101 reward=-6.174869332428392 terminated=False\n",
      "step=102 reward=-6.167131625883596 terminated=False\n",
      "step=103 reward=-6.151370511817339 terminated=False\n",
      "step=104 reward=-6.182126046541465 terminated=False\n",
      "step=105 reward=-6.158998623455784 terminated=False\n",
      "step=106 reward=-6.170426552931322 terminated=False\n",
      "step=107 reward=-6.171473435781115 terminated=False\n",
      "step=108 reward=-6.139345739639517 terminated=False\n",
      "step=109 reward=-6.131915566416588 terminated=False\n",
      "step=110 reward=-6.129350820604279 terminated=False\n",
      "step=111 reward=-6.103694977882028 terminated=False\n",
      "step=112 reward=-6.119382485888799 terminated=False\n",
      "step=113 reward=-6.103338339316773 terminated=False\n",
      "step=114 reward=-6.12878294114565 terminated=False\n",
      "step=115 reward=-6.112854080566521 terminated=False\n",
      "step=116 reward=-6.103514935359943 terminated=False\n",
      "step=117 reward=-6.099807317590332 terminated=False\n",
      "step=118 reward=-6.077769538857915 terminated=False\n",
      "step=119 reward=-6.099765518127095 terminated=False\n",
      "step=120 reward=-6.098216145666042 terminated=False\n",
      "step=121 reward=-6.091039318245936 terminated=False\n",
      "step=122 reward=-6.106814455898043 terminated=False\n",
      "step=123 reward=-6.088342867203306 terminated=False\n",
      "step=124 reward=-6.075361933981425 terminated=False\n",
      "step=125 reward=-6.084015100606353 terminated=False\n",
      "step=126 reward=-6.065743605115015 terminated=False\n",
      "step=127 reward=-6.073193527027149 terminated=False\n",
      "step=128 reward=-6.089566348514982 terminated=False\n",
      "step=129 reward=-6.093426406936914 terminated=False\n",
      "step=130 reward=-6.089444967400619 terminated=False\n",
      "step=131 reward=-6.087217517027952 terminated=False\n",
      "step=132 reward=-6.088132872608779 terminated=False\n",
      "step=133 reward=-6.101027631892292 terminated=False\n",
      "step=134 reward=-6.107751370832046 terminated=False\n",
      "step=135 reward=-6.113545133331252 terminated=False\n",
      "step=136 reward=-6.103401566790135 terminated=False\n",
      "step=137 reward=-6.112319702220085 terminated=False\n",
      "step=138 reward=-6.120057888427434 terminated=False\n",
      "step=139 reward=-6.12089678481029 terminated=False\n",
      "step=140 reward=-6.125639397692673 terminated=False\n",
      "step=141 reward=-6.1277564835987 terminated=False\n",
      "step=142 reward=-6.138787958720897 terminated=False\n",
      "step=143 reward=-6.141913455084181 terminated=False\n",
      "step=144 reward=-6.1403630567326015 terminated=False\n",
      "step=145 reward=-6.150471958185934 terminated=False\n",
      "step=146 reward=-6.157136504961639 terminated=False\n",
      "step=147 reward=-6.160731879384822 terminated=False\n",
      "step=148 reward=-6.1730400441515645 terminated=False\n",
      "step=149 reward=-6.174176770198585 terminated=False\n",
      "step=150 reward=-6.1790394925392995 terminated=False\n",
      "step=151 reward=-6.182246813937544 terminated=False\n",
      "step=152 reward=-6.199591072455016 terminated=False\n",
      "step=153 reward=-6.198213328414081 terminated=False\n",
      "step=154 reward=-6.2017593475137085 terminated=False\n",
      "step=155 reward=-6.210415648542758 terminated=False\n",
      "step=156 reward=-6.219646694784003 terminated=False\n",
      "step=157 reward=-6.22459140279094 terminated=False\n",
      "step=158 reward=-6.231571054744286 terminated=False\n",
      "step=159 reward=-6.23431709423564 terminated=False\n",
      "step=160 reward=-6.244958751178796 terminated=False\n",
      "step=161 reward=-6.256987561296684 terminated=False\n",
      "step=162 reward=-6.261231615751024 terminated=False\n",
      "step=163 reward=-6.272223139520932 terminated=False\n",
      "step=164 reward=-6.285292610771292 terminated=False\n",
      "step=165 reward=-6.2897958773044955 terminated=False\n",
      "step=166 reward=-6.291555040487243 terminated=False\n",
      "step=167 reward=-6.29613422310935 terminated=False\n",
      "step=168 reward=-6.315692381392475 terminated=False\n",
      "step=169 reward=-6.313381831118946 terminated=False\n",
      "step=170 reward=-6.318237747916308 terminated=False\n",
      "step=171 reward=-6.326569168341773 terminated=False\n",
      "step=172 reward=-6.341066827930432 terminated=False\n",
      "step=173 reward=-6.341500724117942 terminated=False\n",
      "step=174 reward=-6.355836709377925 terminated=False\n",
      "step=175 reward=-6.358372908954937 terminated=False\n",
      "step=176 reward=-6.374162227113393 terminated=False\n",
      "step=177 reward=-6.3806096251595665 terminated=False\n",
      "step=178 reward=-6.3899011177393215 terminated=False\n",
      "step=179 reward=-6.401767946811658 terminated=False\n",
      "step=180 reward=-6.4193607708464935 terminated=False\n",
      "step=181 reward=-6.418791558942048 terminated=False\n",
      "step=182 reward=-6.42900598592618 terminated=False\n",
      "step=183 reward=-6.419812543073676 terminated=False\n",
      "step=184 reward=-6.419600758318648 terminated=False\n",
      "step=185 reward=-6.419243715077949 terminated=False\n",
      "step=186 reward=-6.424585923177192 terminated=False\n",
      "step=187 reward=-6.426625411072604 terminated=False\n",
      "step=188 reward=-6.422665911766636 terminated=False\n",
      "step=189 reward=-6.4188257143547425 terminated=False\n",
      "step=190 reward=-6.4234392350579625 terminated=False\n",
      "step=191 reward=-6.420795562970913 terminated=False\n",
      "step=192 reward=-6.422659715010008 terminated=False\n",
      "step=193 reward=-6.424303065005915 terminated=False\n",
      "step=194 reward=-6.424869004199088 terminated=False\n",
      "step=195 reward=-6.41869248745335 terminated=False\n",
      "step=196 reward=-6.429572989262098 terminated=False\n",
      "step=197 reward=-6.427375271564351 terminated=False\n",
      "step=198 reward=-6.42317425590662 terminated=False\n",
      "step=199 reward=-6.430913399110558 terminated=False\n",
      "step=200 reward=-6.261855239035791 terminated=False\n",
      "step=201 reward=-6.234917293150646 terminated=False\n",
      "step=202 reward=-6.234331941156643 terminated=False\n",
      "step=203 reward=-6.224467604428376 terminated=False\n",
      "step=204 reward=-6.228153377394522 terminated=False\n",
      "step=205 reward=-6.222533684837955 terminated=False\n",
      "step=206 reward=-6.21014835559313 terminated=False\n",
      "step=207 reward=-6.222008594541418 terminated=False\n",
      "step=208 reward=-6.203631003336873 terminated=False\n",
      "step=209 reward=-6.206981905901034 terminated=False\n",
      "step=210 reward=-6.198181774987482 terminated=False\n",
      "step=211 reward=-6.194585595683291 terminated=False\n",
      "step=212 reward=-6.1973440824785575 terminated=False\n",
      "step=213 reward=-6.183533307898815 terminated=False\n",
      "step=214 reward=-6.188194285423187 terminated=False\n",
      "step=215 reward=-6.186302796954612 terminated=False\n",
      "step=216 reward=-6.185492146581661 terminated=False\n",
      "step=217 reward=-6.182869342348598 terminated=False\n",
      "step=218 reward=-6.176899219748716 terminated=False\n",
      "step=219 reward=-6.184710044775314 terminated=False\n",
      "step=220 reward=-6.18189442389116 terminated=False\n",
      "step=221 reward=-6.176265276688641 terminated=False\n",
      "step=222 reward=-6.180396414512562 terminated=False\n",
      "step=223 reward=-6.168364145169546 terminated=False\n",
      "step=224 reward=-6.179723980641162 terminated=False\n",
      "step=225 reward=-6.170935053836327 terminated=False\n",
      "step=226 reward=-6.167373626989443 terminated=False\n",
      "step=227 reward=-6.16061895076127 terminated=False\n",
      "step=228 reward=-6.1658560244390195 terminated=False\n",
      "step=229 reward=-6.1617011624597975 terminated=False\n",
      "step=230 reward=-6.158607703923687 terminated=False\n",
      "step=231 reward=-6.1588035799708045 terminated=False\n",
      "step=232 reward=-6.155766815479135 terminated=False\n",
      "step=233 reward=-6.152179913432558 terminated=False\n",
      "step=234 reward=-6.161280727189137 terminated=False\n",
      "step=235 reward=-6.152603727830744 terminated=False\n",
      "step=236 reward=-6.1569081432282715 terminated=False\n",
      "step=237 reward=-6.153230298422297 terminated=False\n",
      "step=238 reward=-6.151811677208549 terminated=False\n",
      "step=239 reward=-6.152241783658813 terminated=False\n",
      "step=240 reward=-6.141793687432429 terminated=False\n",
      "step=241 reward=-6.155727300085733 terminated=False\n",
      "step=242 reward=-6.154812816824032 terminated=False\n",
      "step=243 reward=-6.155191212746511 terminated=False\n",
      "step=244 reward=-6.149275621086792 terminated=False\n",
      "step=245 reward=-6.148804289514274 terminated=False\n",
      "step=246 reward=-6.152522915592165 terminated=False\n",
      "step=247 reward=-6.147544050410634 terminated=False\n",
      "step=248 reward=-6.152338728815258 terminated=False\n",
      "step=249 reward=-6.1468462356642455 terminated=False\n",
      "step=250 reward=-6.146882932937142 terminated=False\n",
      "step=251 reward=-6.143514737953107 terminated=False\n",
      "step=252 reward=-6.1476099012427845 terminated=False\n",
      "step=253 reward=-6.1463922393054675 terminated=False\n",
      "step=254 reward=-6.152732420587968 terminated=False\n",
      "step=255 reward=-6.146051391140455 terminated=False\n",
      "step=256 reward=-6.142743758044006 terminated=False\n",
      "step=257 reward=-6.148484036224777 terminated=False\n",
      "step=258 reward=-6.149819252519746 terminated=False\n",
      "step=259 reward=-6.145137524805097 terminated=False\n",
      "step=260 reward=-6.153308620657453 terminated=False\n",
      "step=261 reward=-6.151673710795105 terminated=False\n",
      "step=262 reward=-6.153214243032146 terminated=False\n",
      "step=263 reward=-6.15136978445288 terminated=False\n",
      "step=264 reward=-6.1579446317840665 terminated=False\n",
      "step=265 reward=-6.1584412927712 terminated=False\n",
      "step=266 reward=-6.154302619139841 terminated=False\n",
      "step=267 reward=-6.147358499407428 terminated=False\n",
      "step=268 reward=-6.157414000351034 terminated=False\n",
      "step=269 reward=-6.152864727102932 terminated=False\n",
      "step=270 reward=-6.162601486962769 terminated=False\n",
      "step=271 reward=-6.156531207043309 terminated=False\n",
      "step=272 reward=-6.156853346868623 terminated=False\n",
      "step=273 reward=-6.158913128052696 terminated=False\n",
      "step=274 reward=-6.158562589964445 terminated=False\n",
      "step=275 reward=-6.157604481009271 terminated=False\n",
      "step=276 reward=-6.164029708244489 terminated=False\n",
      "step=277 reward=-6.15344261106751 terminated=False\n",
      "step=278 reward=-6.163824702838679 terminated=False\n",
      "step=279 reward=-6.156100371652935 terminated=False\n",
      "step=280 reward=-6.172534408073006 terminated=False\n",
      "step=281 reward=-6.162506631152678 terminated=False\n",
      "step=282 reward=-6.164067239412777 terminated=False\n",
      "step=283 reward=-6.168071608045527 terminated=False\n",
      "step=284 reward=-6.1690682567612685 terminated=False\n",
      "step=285 reward=-6.173180050226589 terminated=False\n",
      "step=286 reward=-6.163281464346389 terminated=False\n",
      "step=287 reward=-6.173638302741395 terminated=False\n",
      "step=288 reward=-6.16363262277458 terminated=False\n",
      "step=289 reward=-6.173563451497291 terminated=False\n",
      "step=290 reward=-6.173553242411002 terminated=False\n",
      "step=291 reward=-6.170864346877961 terminated=False\n",
      "step=292 reward=-6.17149222532235 terminated=False\n",
      "step=293 reward=-6.174351111168567 terminated=False\n",
      "step=294 reward=-6.180929585477392 terminated=False\n",
      "step=295 reward=-6.167033550894433 terminated=False\n",
      "step=296 reward=-6.1840729503156275 terminated=False\n",
      "step=297 reward=-6.180351174569267 terminated=False\n",
      "step=298 reward=-6.176294321846965 terminated=False\n",
      "step=299 reward=-6.171470037335988 terminated=False\n",
      "step=300 reward=-6.162439375659096 terminated=False\n",
      "step=301 reward=-6.163239901926348 terminated=False\n",
      "step=302 reward=-6.163066852585221 terminated=False\n",
      "step=303 reward=-6.16994840009926 terminated=False\n",
      "step=304 reward=-6.168152319595729 terminated=False\n",
      "step=305 reward=-6.165242594054812 terminated=False\n",
      "step=306 reward=-6.167073005130571 terminated=False\n",
      "step=307 reward=-6.169681027044427 terminated=False\n",
      "step=308 reward=-6.159684934130718 terminated=False\n",
      "step=309 reward=-6.167009741784647 terminated=False\n",
      "step=310 reward=-6.159202104233031 terminated=False\n",
      "step=311 reward=-6.163880242151367 terminated=False\n",
      "step=312 reward=-6.166955868582651 terminated=False\n",
      "step=313 reward=-6.157167014254551 terminated=False\n",
      "step=314 reward=-6.163620061555416 terminated=False\n",
      "step=315 reward=-6.162759419026038 terminated=False\n",
      "step=316 reward=-6.1567917155912895 terminated=False\n",
      "step=317 reward=-6.163305317901772 terminated=False\n",
      "step=318 reward=-6.162176792781157 terminated=False\n",
      "step=319 reward=-6.174032792193418 terminated=False\n",
      "step=320 reward=-6.164973755347752 terminated=False\n",
      "step=321 reward=-6.170059780770789 terminated=False\n",
      "step=322 reward=-6.172026208076263 terminated=False\n",
      "step=323 reward=-6.169461968879932 terminated=False\n",
      "step=324 reward=-6.171087648979483 terminated=False\n",
      "step=325 reward=-6.166113948757626 terminated=False\n",
      "step=326 reward=-6.1696745137590785 terminated=False\n",
      "step=327 reward=-6.156466693621976 terminated=False\n",
      "step=328 reward=-6.166997953665298 terminated=False\n",
      "step=329 reward=-6.163520718456648 terminated=False\n",
      "step=330 reward=-6.160674623108289 terminated=False\n",
      "step=331 reward=-6.155926345989246 terminated=False\n",
      "step=332 reward=-6.161208320648018 terminated=False\n",
      "step=333 reward=-6.1631823465649465 terminated=False\n",
      "step=334 reward=-6.168194185233952 terminated=False\n",
      "step=335 reward=-6.157376889694821 terminated=False\n",
      "step=336 reward=-6.16369144462805 terminated=False\n",
      "step=337 reward=-6.158340321411913 terminated=False\n",
      "step=338 reward=-6.162641173511213 terminated=False\n",
      "step=339 reward=-6.163189752820637 terminated=False\n",
      "step=340 reward=-6.155127897046334 terminated=False\n",
      "step=341 reward=-6.1600563430264845 terminated=False\n",
      "step=342 reward=-6.154362173532263 terminated=False\n",
      "step=343 reward=-6.1561810804008825 terminated=False\n",
      "step=344 reward=-6.152995345203424 terminated=False\n",
      "step=345 reward=-6.14383912831328 terminated=False\n",
      "step=346 reward=-6.15897780520991 terminated=False\n",
      "step=347 reward=-6.1535224923404845 terminated=False\n",
      "step=348 reward=-6.157329116141245 terminated=False\n",
      "step=349 reward=-6.147794624193837 terminated=False\n",
      "step=350 reward=-6.149742419782319 terminated=False\n",
      "step=351 reward=-6.15110127280368 terminated=False\n",
      "step=352 reward=-6.151747625602652 terminated=False\n",
      "step=353 reward=-6.148052324976477 terminated=False\n",
      "step=354 reward=-6.161706280370289 terminated=False\n",
      "step=355 reward=-6.155129195428978 terminated=False\n",
      "step=356 reward=-6.1584307422928894 terminated=False\n",
      "step=357 reward=-6.151692400149833 terminated=False\n",
      "step=358 reward=-6.15202535467903 terminated=False\n",
      "step=359 reward=-6.146784766306935 terminated=False\n",
      "step=360 reward=-6.1566881919610505 terminated=False\n",
      "step=361 reward=-6.159411574702741 terminated=False\n",
      "step=362 reward=-6.160180414991991 terminated=False\n",
      "step=363 reward=-6.15873114460789 terminated=False\n",
      "step=364 reward=-6.157551642550811 terminated=False\n",
      "step=365 reward=-6.161140227741642 terminated=False\n",
      "step=366 reward=-6.154213521676338 terminated=False\n",
      "step=367 reward=-6.150250935825373 terminated=False\n",
      "step=368 reward=-6.161868054568831 terminated=False\n",
      "step=369 reward=-6.154590485598844 terminated=False\n",
      "step=370 reward=-6.1655073614112785 terminated=False\n",
      "step=371 reward=-6.158285538517283 terminated=False\n",
      "step=372 reward=-6.15892510690904 terminated=False\n",
      "step=373 reward=-6.163638896459938 terminated=False\n",
      "step=374 reward=-6.157062563459385 terminated=False\n",
      "step=375 reward=-6.156189454926624 terminated=False\n",
      "step=376 reward=-6.160977807471015 terminated=False\n",
      "step=377 reward=-6.14655415915143 terminated=False\n",
      "step=378 reward=-6.154709041338201 terminated=False\n",
      "step=379 reward=-6.154509583404877 terminated=False\n",
      "step=380 reward=-6.16987587586802 terminated=False\n",
      "step=381 reward=-6.15519963492147 terminated=False\n",
      "step=382 reward=-6.150104588635363 terminated=False\n",
      "step=383 reward=-6.1630394053486945 terminated=False\n",
      "step=384 reward=-6.15919335019167 terminated=False\n",
      "step=385 reward=-6.1591243551158605 terminated=False\n",
      "step=386 reward=-6.152219184629425 terminated=False\n",
      "step=387 reward=-6.1490415693903975 terminated=False\n",
      "step=388 reward=-6.143477875906248 terminated=False\n",
      "step=389 reward=-6.157376665753027 terminated=False\n",
      "step=390 reward=-6.152354178508533 terminated=False\n",
      "step=391 reward=-6.152910353630565 terminated=False\n",
      "step=392 reward=-6.149939419540912 terminated=False\n",
      "step=393 reward=-6.148358888113393 terminated=False\n",
      "step=394 reward=-6.1505041384681 terminated=False\n",
      "step=395 reward=-6.13123533767939 terminated=False\n",
      "step=396 reward=-6.1522824163930565 terminated=False\n",
      "step=397 reward=-6.148052894241152 terminated=False\n",
      "step=398 reward=-6.141691675200988 terminated=False\n",
      "step=399 reward=-6.141513064131443 terminated=False\n",
      "step=400 reward=-6.162438834499865 terminated=False\n",
      "step=401 reward=-6.163239473661436 terminated=False\n",
      "step=402 reward=-6.163066183028498 terminated=False\n",
      "step=403 reward=-6.169947990376937 terminated=False\n",
      "step=404 reward=-6.168151821538384 terminated=False\n",
      "step=405 reward=-6.165241742182882 terminated=False\n",
      "step=406 reward=-6.167072475547061 terminated=False\n",
      "step=407 reward=-6.169680058161346 terminated=False\n",
      "step=408 reward=-6.159684283259616 terminated=False\n",
      "step=409 reward=-6.1670092355109745 terminated=False\n",
      "step=410 reward=-6.159201660259625 terminated=False\n",
      "step=411 reward=-6.163879965038496 terminated=False\n",
      "step=412 reward=-6.166955395698462 terminated=False\n",
      "step=413 reward=-6.157166610513826 terminated=False\n",
      "step=414 reward=-6.163619662174128 terminated=False\n",
      "step=415 reward=-6.162758978226006 terminated=False\n",
      "step=416 reward=-6.156791528002623 terminated=False\n",
      "step=417 reward=-6.163304942243263 terminated=False\n",
      "step=418 reward=-6.162176229643686 terminated=False\n",
      "step=419 reward=-6.174032428423909 terminated=False\n",
      "step=420 reward=-6.16497339997016 terminated=False\n",
      "step=421 reward=-6.170059481936704 terminated=False\n",
      "step=422 reward=-6.17202591057524 terminated=False\n",
      "step=423 reward=-6.169461489802627 terminated=False\n",
      "step=424 reward=-6.171087625686733 terminated=False\n",
      "step=425 reward=-6.166113627069198 terminated=False\n",
      "step=426 reward=-6.16967400065853 terminated=False\n",
      "step=427 reward=-6.156466426483991 terminated=False\n",
      "step=428 reward=-6.166997799411283 terminated=False\n",
      "step=429 reward=-6.163519768548385 terminated=False\n",
      "step=430 reward=-6.160674330025314 terminated=False\n",
      "step=431 reward=-6.15592561087467 terminated=False\n",
      "step=432 reward=-6.161207693153013 terminated=False\n",
      "step=433 reward=-6.16318207357189 terminated=False\n",
      "step=434 reward=-6.16819371227284 terminated=False\n",
      "step=435 reward=-6.157376729966829 terminated=False\n",
      "step=436 reward=-6.163691183648927 terminated=False\n",
      "step=437 reward=-6.158340168143738 terminated=False\n",
      "step=438 reward=-6.162640883400741 terminated=False\n",
      "step=439 reward=-6.163189565113546 terminated=False\n",
      "step=440 reward=-6.1551270178751505 terminated=False\n",
      "step=441 reward=-6.160056211929019 terminated=False\n",
      "step=442 reward=-6.154361799928752 terminated=False\n",
      "step=443 reward=-6.156180209182455 terminated=False\n",
      "step=444 reward=-6.1529949827701405 terminated=False\n",
      "step=445 reward=-6.143838816606151 terminated=False\n",
      "step=446 reward=-6.158977743267042 terminated=False\n",
      "step=447 reward=-6.153522287781632 terminated=False\n",
      "step=448 reward=-6.157328858686299 terminated=False\n",
      "step=449 reward=-6.147794577021344 terminated=False\n",
      "step=450 reward=-6.14974217951607 terminated=False\n",
      "step=451 reward=-6.151100990927631 terminated=False\n",
      "step=452 reward=-6.151747391940429 terminated=False\n",
      "step=453 reward=-6.148052143794166 terminated=False\n",
      "step=454 reward=-6.1617061114350475 terminated=False\n",
      "step=455 reward=-6.155128372703851 terminated=False\n",
      "step=456 reward=-6.158430425905905 terminated=False\n",
      "step=457 reward=-6.151692232493921 terminated=False\n",
      "step=458 reward=-6.152025194988504 terminated=False\n",
      "step=459 reward=-6.146784604755416 terminated=False\n",
      "step=460 reward=-6.156688486594231 terminated=False\n",
      "step=461 reward=-6.15941142114445 terminated=False\n",
      "step=462 reward=-6.160180368204239 terminated=False\n",
      "step=463 reward=-6.158731048188178 terminated=False\n",
      "step=464 reward=-6.15755159705459 terminated=False\n",
      "step=465 reward=-6.161140031189648 terminated=False\n",
      "step=466 reward=-6.15421339125113 terminated=False\n",
      "step=467 reward=-6.150250652537379 terminated=False\n",
      "step=468 reward=-6.161867875400661 terminated=False\n",
      "step=469 reward=-6.154590459607411 terminated=False\n",
      "step=470 reward=-6.165507188192464 terminated=False\n",
      "step=471 reward=-6.158285414229988 terminated=False\n",
      "step=472 reward=-6.158924982336991 terminated=False\n",
      "step=473 reward=-6.163638575992174 terminated=False\n",
      "step=474 reward=-6.157061948930662 terminated=False\n",
      "step=475 reward=-6.156189435573692 terminated=False\n",
      "step=476 reward=-6.1609777410244675 terminated=False\n",
      "step=477 reward=-6.146554007158521 terminated=False\n",
      "step=478 reward=-6.15470823638087 terminated=False\n",
      "step=479 reward=-6.15450933280847 terminated=False\n",
      "step=480 reward=-6.169875824391579 terminated=False\n",
      "step=481 reward=-6.155199438285726 terminated=False\n",
      "step=482 reward=-6.150104492548824 terminated=False\n",
      "step=483 reward=-6.163039314734534 terminated=False\n",
      "step=484 reward=-6.159193901857823 terminated=False\n",
      "step=485 reward=-6.159124766827864 terminated=False\n",
      "step=486 reward=-6.152218850102448 terminated=False\n",
      "step=487 reward=-6.149041142836959 terminated=False\n",
      "step=488 reward=-6.143477792147966 terminated=False\n",
      "step=489 reward=-6.157376875591684 terminated=False\n",
      "step=490 reward=-6.1523539476229185 terminated=False\n",
      "step=491 reward=-6.152909584848192 terminated=False\n",
      "step=492 reward=-6.149939294969643 terminated=False\n",
      "step=493 reward=-6.148358302718215 terminated=False\n",
      "step=494 reward=-6.150504102110109 terminated=False\n",
      "step=495 reward=-6.131235265030975 terminated=False\n",
      "step=496 reward=-6.152282246629216 terminated=False\n",
      "step=497 reward=-6.148052826053449 terminated=False\n",
      "step=498 reward=-6.141691457214709 terminated=False\n",
      "step=499 reward=-6.1415129489296145 terminated=False\n",
      "Failure!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Image data must be a sequence of ndimages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailure!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m \u001b[43mimageio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmimsave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m5_so100.mp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo of the evaluation is available in 5_so100.mp4.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/git/robotics/gym-so100/venv/lib/python3.10/site-packages/imageio/v2.py:490\u001b[0m, in \u001b[0;36mmimwrite\u001b[0;34m(uri, ims, format, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"mimwrite(uri, ims, format=None, **kwargs)\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03mWrite multiple images to the specified file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03m    to see what arguments are available for a particular format.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batch(ims):\n\u001b[0;32m--> 490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage data must be a sequence of ndimages.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    492\u001b[0m imopen_args \u001b[38;5;241m=\u001b[39m decypher_format_arg(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m    493\u001b[0m imopen_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Image data must be a sequence of ndimages."
     ]
    }
   ],
   "source": [
    "from lerobot.common.policies.act.modeling_act import ACTPolicy\n",
    "pretrained_path = \"/home/absin/Documents/git/robotics/act_algorithm/trained_model/act_aloha_sim_transfer_cube_human\"\n",
    "policy = ACTPolicy.from_pretrained(pretrained_path)\n",
    "policy.reset()\n",
    "numpy_observation, info = env.reset(seed=42)\n",
    "rewards = []\n",
    "frames = []\n",
    "# Render frame of the initial state\n",
    "frames.append(env.render())\n",
    "step = 0\n",
    "done = False\n",
    "device = 'cpu'\n",
    "while not done:\n",
    "    # Prepare observation for the policy running in Pytorch\n",
    "    state = torch.from_numpy(numpy_observation[\"agent_pos\"])\n",
    "    image = torch.from_numpy(numpy_observation[\"image_top\"])\n",
    "    state = torch.zeros(14)\n",
    "    state[:numpy_observation[\"agent_pos\"].shape[0]] = torch.from_numpy(numpy_observation[\"agent_pos\"])\n",
    "    # Convert to float32 with image from channel first in [0,255]\n",
    "    # to channel last in [0,1]\n",
    "    state = state.to(torch.float32)\n",
    "    image = image.to(torch.float32) / 255\n",
    "    image = image.permute(2, 0, 1)\n",
    "\n",
    "    # Send data tensors from CPU to GPU\n",
    "    state = state.to(device, non_blocking=True)\n",
    "    image = image.to(device, non_blocking=True)\n",
    "\n",
    "    # Add extra (empty) batch dimension, required to forward the policy\n",
    "    state = state.unsqueeze(0)\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    # Create the policy input dictionary\n",
    "    observation = {\n",
    "        \"observation.state\": state,\n",
    "        \"observation.images.top\": image,\n",
    "    }\n",
    "\n",
    "    # Predict the next action with respect to the current observation\n",
    "    with torch.inference_mode():\n",
    "        action = policy.select_action(observation)\n",
    "\n",
    "    # Prepare the action for the environment\n",
    "    numpy_action = action.squeeze(0).to(\"cpu\").numpy()\n",
    "\n",
    "    # Step through the environment and receive a new observation\n",
    "    numpy_observation, reward, terminated, truncated, info = env.step(numpy_action[:6])\n",
    "    print(f\"{step=} {reward=} {terminated=}\")\n",
    "\n",
    "    # Keep track of all the rewards and frames\n",
    "    rewards.append(reward)\n",
    "    frames.append(env.render())\n",
    "\n",
    "    # The rollout is considered done when the success state is reach (i.e. terminated is True),\n",
    "    # or the maximum number of iterations is reached (i.e. truncated is True)\n",
    "    done = terminated | truncated | done\n",
    "    step += 1\n",
    "\n",
    "if terminated:\n",
    "    print(\"Success!\")\n",
    "else:\n",
    "    print(\"Failure!\")\n",
    "\n",
    "imageio.mimsave('5_so100.mp4', numpy.stack(frames), fps=25)\n",
    "print(f\"Video of the evaluation is available in 5_so100.mp4.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40e0c677-bde5-49b6-aa6a-93c588610e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent_pos': array([-2.2       , -3.1416435 ,  3.141698  , -2.0000236 , -3.141577  ,\n",
       "        -0.20000166], dtype=float32),\n",
       " 'agent_vel': array([-8.6965530e-14, -1.0769277e-13, -1.0667864e-13, -1.0825468e-13,\n",
       "         3.2166736e-09, -5.4392504e-15], dtype=float32),\n",
       " 'target_pos': array([ 0.0273956 , -0.20244487,  0.01      ], dtype=float32),\n",
       " 'image_front': array([[[39, 66, 92],\n",
       "         [39, 66, 92],\n",
       "         [39, 66, 92],\n",
       "         ...,\n",
       "         [39, 66, 92],\n",
       "         [39, 66, 92],\n",
       "         [39, 66, 92]],\n",
       " \n",
       "        [[39, 66, 92],\n",
       "         [39, 66, 92],\n",
       "         [39, 66, 92],\n",
       "         ...,\n",
       "         [39, 66, 92],\n",
       "         [39, 66, 92],\n",
       "         [39, 66, 92]],\n",
       " \n",
       "        [[39, 65, 92],\n",
       "         [39, 65, 92],\n",
       "         [39, 65, 92],\n",
       "         ...,\n",
       "         [39, 65, 92],\n",
       "         [39, 65, 92],\n",
       "         [39, 65, 92]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[29, 59, 87],\n",
       "         [29, 59, 87],\n",
       "         [29, 59, 87],\n",
       "         ...,\n",
       "         [29, 59, 88],\n",
       "         [29, 59, 88],\n",
       "         [29, 59, 88]],\n",
       " \n",
       "        [[29, 59, 87],\n",
       "         [29, 59, 87],\n",
       "         [29, 59, 87],\n",
       "         ...,\n",
       "         [29, 59, 88],\n",
       "         [29, 59, 88],\n",
       "         [29, 59, 88]],\n",
       " \n",
       "        [[29, 59, 87],\n",
       "         [29, 59, 87],\n",
       "         [34, 63, 91],\n",
       "         ...,\n",
       "         [29, 59, 88],\n",
       "         [29, 59, 88],\n",
       "         [29, 59, 88]]], dtype=uint8),\n",
       " 'image_top': array([[[ 77, 114, 154],\n",
       "         [ 77, 114, 154],\n",
       "         [ 77, 114, 154],\n",
       "         ...,\n",
       "         [ 37,  77, 114],\n",
       "         [ 37,  77, 114],\n",
       "         [ 37,  77, 114]],\n",
       " \n",
       "        [[ 77, 114, 154],\n",
       "         [ 77, 114, 154],\n",
       "         [ 77, 114, 154],\n",
       "         ...,\n",
       "         [ 37,  77, 114],\n",
       "         [ 37,  77, 114],\n",
       "         [ 37,  77, 114]],\n",
       " \n",
       "        [[ 77, 114, 154],\n",
       "         [ 77, 114, 154],\n",
       "         [ 77, 114, 154],\n",
       "         ...,\n",
       "         [ 37,  77, 114],\n",
       "         [ 37,  77, 114],\n",
       "         [ 37,  77, 114]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 79, 117, 158],\n",
       "         [ 79, 117, 158],\n",
       "         [ 79, 117, 158],\n",
       "         ...,\n",
       "         [ 38,  79, 117],\n",
       "         [ 38,  79, 117],\n",
       "         [ 38,  79, 117]],\n",
       " \n",
       "        [[ 79, 117, 158],\n",
       "         [ 79, 117, 158],\n",
       "         [ 79, 117, 158],\n",
       "         ...,\n",
       "         [ 38,  79, 117],\n",
       "         [ 38,  79, 117],\n",
       "         [ 38,  79, 117]],\n",
       " \n",
       "        [[ 79, 117, 158],\n",
       "         [ 79, 117, 158],\n",
       "         [ 79, 117, 158],\n",
       "         ...,\n",
       "         [ 38,  79, 117],\n",
       "         [ 38,  79, 117],\n",
       "         [ 38,  79, 117]]], dtype=uint8)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47b741b4-7bde-4cf9-aba0-8b9789be8bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_agent_pos = torch.zeros(14)\n",
    "padded_agent_pos[:numpy_observation[\"agent_pos\"].shape[0]] = torch.from_numpy(numpy_observation[\"agent_pos\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac1a889f-68f5-4c3d-8e45-c010e76cff59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_agent_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c6e4d44-ed97-4fc7-a444-8683f2714c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.6.0\n",
      "Uninstalling torch-2.6.0:\n",
      "  Would remove:\n",
      "    /home/absin/Documents/git/robotics/gym-so100/venv/bin/torchfrtrace\n",
      "    /home/absin/Documents/git/robotics/gym-so100/venv/bin/torchrun\n",
      "    /home/absin/Documents/git/robotics/gym-so100/venv/lib/python3.10/site-packages/functorch/*\n",
      "    /home/absin/Documents/git/robotics/gym-so100/venv/lib/python3.10/site-packages/torch-2.6.0.dist-info/*\n",
      "    /home/absin/Documents/git/robotics/gym-so100/venv/lib/python3.10/site-packages/torch/*\n",
      "    /home/absin/Documents/git/robotics/gym-so100/venv/lib/python3.10/site-packages/torchgen/*\n",
      "^Coceed (Y/n)? \n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb169217-6910-42ba-954b-15679a8d41f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
