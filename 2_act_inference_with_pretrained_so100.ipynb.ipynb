{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfaa117-038a-4b42-8718-69cddcec8685",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/jpata/gym-so100.git@integration\n",
    "!pip install imageio torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f09406b3-d3d5-4117-811e-75f3d9c9dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import gym_so100\n",
    "import numpy\n",
    "#import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91bd914a-4677-4e1e-b001-31d04f879983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/absin/Documents/gym-so100/venv/lib/python3.12/site-packages/glfw/__init__.py:917: GLFWError: (65548) b'Wayland: The platform does not provide the window position'\n",
      "  warnings.warn(message, GLFWError)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"gym_so100/PushCube-v0\", render_mode=\"human\")\n",
    "observation, info = env.reset()\n",
    "\n",
    "frames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "133a3a2a-0410-4427-bac0-fc41a8c0ab64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent_pos': array([ 0.  , -3.14,  3.  ,  1.24,  0.  ,  0.  ], dtype=float32),\n",
       " 'agent_vel': array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " 'target_pos': array([ 0.01823854, -0.18954605,  0.01      ], dtype=float32),\n",
       " 'image_front': array([[[39, 66, 92],\n",
       "         [39, 66, 92],\n",
       "         [39, 66, 92],\n",
       "         ...,\n",
       "         [39, 66, 92],\n",
       "         [39, 66, 92],\n",
       "         [39, 66, 92]],\n",
       " \n",
       "        [[39, 66, 92],\n",
       "         [39, 66, 92],\n",
       "         [39, 66, 92],\n",
       "         ...,\n",
       "         [39, 66, 92],\n",
       "         [39, 66, 92],\n",
       "         [39, 66, 92]],\n",
       " \n",
       "        [[39, 65, 92],\n",
       "         [39, 65, 92],\n",
       "         [39, 65, 92],\n",
       "         ...,\n",
       "         [39, 65, 92],\n",
       "         [39, 65, 92],\n",
       "         [39, 65, 92]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[29, 59, 87],\n",
       "         [29, 59, 87],\n",
       "         [29, 59, 87],\n",
       "         ...,\n",
       "         [29, 59, 88],\n",
       "         [29, 59, 88],\n",
       "         [29, 59, 88]],\n",
       " \n",
       "        [[29, 59, 87],\n",
       "         [29, 59, 87],\n",
       "         [29, 59, 87],\n",
       "         ...,\n",
       "         [29, 59, 88],\n",
       "         [29, 59, 88],\n",
       "         [29, 59, 88]],\n",
       " \n",
       "        [[29, 59, 87],\n",
       "         [29, 59, 87],\n",
       "         [34, 63, 91],\n",
       "         ...,\n",
       "         [29, 59, 88],\n",
       "         [29, 59, 88],\n",
       "         [29, 59, 88]]], shape=(240, 320, 3), dtype=uint8),\n",
       " 'image_top': array([[[ 77, 114, 154],\n",
       "         [ 77, 114, 154],\n",
       "         [ 77, 114, 154],\n",
       "         ...,\n",
       "         [ 37,  77, 114],\n",
       "         [ 37,  77, 114],\n",
       "         [ 37,  77, 114]],\n",
       " \n",
       "        [[ 77, 114, 154],\n",
       "         [ 77, 114, 154],\n",
       "         [ 77, 114, 154],\n",
       "         ...,\n",
       "         [ 37,  77, 114],\n",
       "         [ 37,  77, 114],\n",
       "         [ 37,  77, 114]],\n",
       " \n",
       "        [[ 77, 114, 154],\n",
       "         [ 77, 114, 154],\n",
       "         [ 77, 114, 154],\n",
       "         ...,\n",
       "         [ 37,  77, 114],\n",
       "         [ 37,  77, 114],\n",
       "         [ 37,  77, 114]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 79, 117, 158],\n",
       "         [ 79, 117, 158],\n",
       "         [ 79, 117, 158],\n",
       "         ...,\n",
       "         [ 38,  79, 117],\n",
       "         [ 38,  79, 117],\n",
       "         [ 38,  79, 117]],\n",
       " \n",
       "        [[ 79, 117, 158],\n",
       "         [ 79, 117, 158],\n",
       "         [ 79, 117, 158],\n",
       "         ...,\n",
       "         [ 38,  79, 117],\n",
       "         [ 38,  79, 117],\n",
       "         [ 38,  79, 117]],\n",
       " \n",
       "        [[ 79, 117, 158],\n",
       "         [ 79, 117, 158],\n",
       "         [ 79, 117, 158],\n",
       "         ...,\n",
       "         [ 38,  79, 117],\n",
       "         [ 38,  79, 117],\n",
       "         [ 38,  79, 117]]], shape=(240, 320, 3), dtype=uint8)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cec10f9-674a-4cd2-9a8d-99da7ccdfbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-1.0, 1.0, (6,), float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d09be0c-bdb5-445f-8927-c96571aff84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mujoco._structs.MjModel at 0x71be3014a5f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unwrapped.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dc9dcfb-bc46-482b-b10d-96a2e8c89ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/absin/Documents/gym-so100/venv/lib/python3.12/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    }
   ],
   "source": [
    "numpy_observation, reward, terminated, truncated, info = env.step(np.array([+5,0,0,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2f444bf-3943-4182-8470-ea02845bfc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_success': np.False_}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07055539-813c-40b2-9cf4-17be0c861cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynput.keyboard import Key, Listener\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b4634c-2b8c-43e7-a144-eafbfb1bb6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(key):\n",
    "    if key == Key.delete:\n",
    "        # Stop listener\n",
    "        return False\n",
    "    \n",
    "    if key.char == 'q':\n",
    "        env.step(np.array([-5,0,0,0,0,0]))\n",
    "    if key.char == 'w':\n",
    "        env.step(np.array([5,0,0,0,0,0]))\n",
    "\n",
    "    if key.char == 'a':\n",
    "        env.step(np.array([0,5,0,0,0,0]))\n",
    "    if key.char == 's':\n",
    "        env.step(np.array([0,-5,0,0,0,0]))\n",
    "\n",
    "    if key.char == 'z':\n",
    "        env.step(np.array([0,0,5,0,0,0]))\n",
    "    if key.char == 'x':\n",
    "        env.step(np.array([0,0,-5,0,0,0]))\n",
    "\n",
    "    if key.char == 'o':\n",
    "        env.step(np.array([0,0,0,-5,0,0]))\n",
    "    if key.char == 'p':\n",
    "        env.step(np.array([0,0,0,5,0,0]))\n",
    "\n",
    "    if key.char == 'k':\n",
    "        env.step(np.array([0,0,0,0,-5,0]))\n",
    "    if key.char == 'l':\n",
    "        env.step(np.array([0,0,0,0,5,0]))\n",
    "\n",
    "    if key.char == 'n':\n",
    "        env.step(np.array([0,0,0,0,0,-5]))\n",
    "    if key.char == 'm':\n",
    "        env.step(np.array([0,0,0,0,0,5]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf3782e-d024-49be-9297-a5b3305aeea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/absin/Documents/gym-so100/venv/lib/python3.12/site-packages/glfw/__init__.py:917: GLFWError: (65544) b'EGL: Failed to make context current: EGL cannot access a requested resource'\n",
      "  warnings.warn(message, GLFWError)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Collect all event  released\n",
    "with Listener(on_press = show) as listener:   \n",
    "   listener.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d8d1599-f171-45a7-920d-7f37d4e1584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e6cfb-b4c1-4e9f-9877-50d7f7bbcabe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abca1d68-f18e-4447-8d53-105e4e822c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bd13ff-b20f-4421-8ff2-d4571c32ae2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e3c03-48af-4bdb-b81e-931972db3e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1599ef-5f39-45f5-860d-d7a04524c73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f922917-73dd-469d-aa53-e1fb032a4036",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca465d4-7782-4d21-a1bc-e3d17575937d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2169c9e8-e48a-4aad-946e-f809c1de5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b0571-9ae4-483e-8ee0-4bcb75adfded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3910b419-ff8a-4262-80d6-8069df856a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34d17f3-e550-4754-af8a-daefcbbb3c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f3b9c-d26b-4388-90d7-931088913f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.common.policies.act.modeling_act import ACTPolicy\n",
    "pretrained_path = \"/home/absin/Documents/git/robotics/act_algorithm/trained_model/act_aloha_sim_transfer_cube_human\"\n",
    "policy = ACTPolicy.from_pretrained(pretrained_path)\n",
    "policy.reset()\n",
    "numpy_observation, info = env.reset(seed=42)\n",
    "rewards = []\n",
    "frames = []\n",
    "# Render frame of the initial state\n",
    "frames.append(env.render())\n",
    "step = 0\n",
    "done = False\n",
    "device = 'cpu'\n",
    "while not done:\n",
    "    # Prepare observation for the policy running in Pytorch\n",
    "    state = torch.from_numpy(numpy_observation[\"agent_pos\"])\n",
    "    image = torch.from_numpy(numpy_observation[\"image_top\"])\n",
    "    state = torch.zeros(14)\n",
    "    state[:numpy_observation[\"agent_pos\"].shape[0]] = torch.from_numpy(numpy_observation[\"agent_pos\"])\n",
    "    # Convert to float32 with image from channel first in [0,255]\n",
    "    # to channel last in [0,1]\n",
    "    state = state.to(torch.float32)\n",
    "    image = image.to(torch.float32) / 255\n",
    "    image = image.permute(2, 0, 1)\n",
    "\n",
    "    # Send data tensors from CPU to GPU\n",
    "    state = state.to(device, non_blocking=True)\n",
    "    image = image.to(device, non_blocking=True)\n",
    "\n",
    "    # Add extra (empty) batch dimension, required to forward the policy\n",
    "    state = state.unsqueeze(0)\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    # Create the policy input dictionary\n",
    "    observation = {\n",
    "        \"observation.state\": state,\n",
    "        \"observation.images.top\": image,\n",
    "    }\n",
    "\n",
    "    # Predict the next action with respect to the current observation\n",
    "    with torch.inference_mode():\n",
    "        action = policy.select_action(observation)\n",
    "\n",
    "    # Prepare the action for the environment\n",
    "    numpy_action = action.squeeze(0).to(\"cpu\").numpy()\n",
    "\n",
    "    # Step through the environment and receive a new observation\n",
    "    numpy_observation, reward, terminated, truncated, info = env.step(numpy_action[:6])\n",
    "    print(f\"{step=} {reward=} {terminated=}\")\n",
    "\n",
    "    # Keep track of all the rewards and frames\n",
    "    rewards.append(reward)\n",
    "    frames.append(env.render())\n",
    "\n",
    "    # The rollout is considered done when the success state is reach (i.e. terminated is True),\n",
    "    # or the maximum number of iterations is reached (i.e. truncated is True)\n",
    "    done = terminated | truncated | done\n",
    "    step += 1\n",
    "\n",
    "if terminated:\n",
    "    print(\"Success!\")\n",
    "else:\n",
    "    print(\"Failure!\")\n",
    "\n",
    "imageio.mimsave('5_so100.mp4', numpy.stack(frames), fps=25)\n",
    "print(f\"Video of the evaluation is available in 5_so100.mp4.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e0c677-bde5-49b6-aa6a-93c588610e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b741b4-7bde-4cf9-aba0-8b9789be8bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_agent_pos = torch.zeros(14)\n",
    "padded_agent_pos[:numpy_observation[\"agent_pos\"].shape[0]] = torch.from_numpy(numpy_observation[\"agent_pos\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a889f-68f5-4c3d-8e45-c010e76cff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_agent_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6e4d44-ed97-4fc7-a444-8683f2714c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb169217-6910-42ba-954b-15679a8d41f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
